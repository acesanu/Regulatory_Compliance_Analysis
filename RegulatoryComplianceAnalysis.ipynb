{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVT7tPQbK7VZokFCalj8nb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acesanu/Regulatory_Compliance_Analysis/blob/main/RegulatoryComplianceAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Introduction\n",
        "According to the Consumer Response Annual Report of Consumer Financial Protection Bureau(CFPB), the Bureau sent approximately 264,100 (or 80%) of these complaints to companies for review and response, referred 14% complaints received to other regulatory agencies. and found 4% to be incomplete"
      ],
      "metadata": {
        "id": "_Q4nrbU8yHZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q 11: What are the Most Common Words in Neutral Reviews?\n",
        "# For neutral reviews, we are setting star_rating to 3 and polarity to 0.\n",
        "\n",
        "wordcloud = WordCloud(width=2500, height=2000, max_words=50,\n",
        "                      background_color='White').generate(str(reviews_df[reviews_df['star_rating'] ==3) &\n",
        "                                                    (reviews_df['polarity'] ==0)].sample(10000, random_state=0)['clean_reviews']))"
      ],
      "metadata": {
        "id": "mCQnXgUsSzde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "1l0gtSGaTsbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "The most common words for neutral reviews are charge, use, monitor, anyone, etc\n",
        "These words don't express a clear sentiment and hence are appropriate for neutral reviews."
      ],
      "metadata": {
        "id": "cnQg90v2T0sq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q 12: What are the Most Common words in Negative Reviews?\n",
        "\n",
        "# For negative reviews, we are setting star_rating to 1 and polarity to -1.\n",
        "\n",
        "wordcloud = WordCloud(width=2500, height=2000, max_words=50,\n",
        "                      background_color= 'White').generate(str(reviews_df[(reviews_df['star_rating']== 1) &\n",
        "                                                      (reviews_df['polarity'] == -1)]['clean_reviews']))"
      ],
      "metadata": {
        "id": "lVdV9qXDUNzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize= (10, 10))\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "H2pgiZ0GVRVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation:\n",
        "1) The most common words for negative reviews are horrible, worst, terrible, awful, broke etc\n",
        "2) These words clearly express a negative emotion and are appropriate for negative reviews."
      ],
      "metadata": {
        "id": "NL4oFthTVYA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Post Data Processing & Analysis\n",
        "\n",
        "1) After completing the analysis on the data, we can move on towards fitting our Machine Learning models with our data.\n",
        "2) But, our dataset still contains a lot of redundant columns in our data which won't help the model in making predictions\n",
        "3) Also, we need to remove samples having subjectively lower than the subjectivity threshold value of 0.3\n",
        "4) And, we need to create a sentiment column containing the labels for our machine learning model.\n",
        "5) In this section, we will remove all the redundant columns, drop samples that doesn't satisfy our selection criteria, and then create a sentiment column.\n",
        "6) We will also be splitting the data into two subsets for training and testing purposes."
      ],
      "metadata": {
        "id": "NjnO8vMzVqJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing Redundant columns\n",
        "# We will remove every redundant column from our dataset\n",
        "# We will create a new dataframe containing only the essential features and use this dataframe down the line.\n",
        "\n",
        "essential_df = reviews_df[['star_rating', 'clean_reviews', 'polarity', 'subjectivity']]\n",
        "essential_df.head()\n",
        "\n",
        "# The new dataframe only contains the essential features: star_rating, clean_reviews_ polarity, subjectivity."
      ],
      "metadata": {
        "id": "Bd8ORh0mWkAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing Samples having Subjectivity less than 0.3\n",
        "# Here, we will remove the samples having subjectivity lower than the subjectivity threshold value of 0.3\n",
        "\n",
        "essential_df['subjectivity'].min()\n"
      ],
      "metadata": {
        "id": "l9ANAVf7XO5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "essential_df = essential_df[essential_df['subjectivity'] >= 0.3]"
      ],
      "metadata": {
        "id": "nEnGmHdKXimX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the minimum value of subjectivity after removing samples\n",
        "essential_df['subjectivity'].min()\n",
        "\n",
        "# The minimum value of subjectivity has increased frok 0 to 0.3\n",
        "# We have successfully removed every sample having subjectivity less than 0.3"
      ],
      "metadata": {
        "id": "S60VjXz3XwYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Sentiment Column\n",
        "Now, we will create a sentiment column which will provide the labels for our training samples used in the Machine Learning models.\n",
        "We will use both the star_rating and polarity values to divide our reviews into different sentiments.\n",
        "\n",
        "For positive reviews, we are using a star_rating higher than 3 and a polarity value greater than or equal to 0.5\n",
        "We have to use such a high value of polarity due to the large volume of positive reviews.\n",
        "We need to reduce the size of our dataset for training, otherwise our session will crash, due to shortage of RAM."
      ],
      "metadata": {
        "id": "EUirckSxYJQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "essential_df[(essential_df['star_rating'] > 3) & (essential_df['polarity'] >= 0.5)].head()"
      ],
      "metadata": {
        "id": "lxa6gjFrZFyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_df = essential_df[(essential_df['star_rating'] > 3) & essential_df['polarity'] >=0.5)]"
      ],
      "metadata": {
        "id": "34-JPt0EZXmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_df['sentiment'] = 'positive'"
      ],
      "metadata": {
        "id": "5spURKj0ZpO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_df.head()\n",
        "\n",
        "# For neutral reviews, we are using a star_rating equal to 3 and a polarity value between -0.1 and 0.1\n",
        "\n",
        "essential_df[(essential_df['star_rating'] == 3) & (essential_df['polarity'] >=-0.1) & (essential_df['polarity'] <= 0.1)].head()\n",
        "\n",
        "neutral_df = essential_df[(essential_df['star_rating'] == 3) & (essential_df['polairty'] >= 10.1) & (essential_df['polarity'] <= 0.1)]\n",
        "\n",
        "neutral_df['sentiment']  = 'neutral'\n",
        "\n",
        "neutral_df.head()"
      ],
      "metadata": {
        "id": "lRCNO4g4ZtEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For negative reviews, we are using a star_rating less than 3 and a polarity value less than 0.\n",
        "\n",
        "essential_df[(essential_df['star_rating'] < 3) & (essential_df['polarity'] < 0)].head()\n",
        "\n",
        "negative_df = essential_df[(essential_df['star_rating'] <3) & (essential_df['polarity'] <0)]\n",
        "\n",
        "negative_df['sentiment'] = 'negative'\n",
        "\n",
        "negative_df.head()"
      ],
      "metadata": {
        "id": "T-3QV_tLbpsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Joining all 3 dataframes to create our final dataset\n",
        "\n",
        "sentiment_df = pd.concat([positive_df, neutral_df, negative_df], ignore_index=True)\n",
        "sentiment_df.head()\n",
        "\n",
        "sentiment_df.tail()\n",
        "\n",
        "# The final dataset contains the selected reviews along with their respective sentiments."
      ],
      "metadata": {
        "id": "fosw2bKpczXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Proportional Distribution of Sentiments\n",
        "# Plotting the proportional distribution of sentiments\n",
        "sentiment_df['sentiment'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=80, figsize=(8, 8),\n",
        "                                              fontsize=14, legend=True, cmap='summer')\n",
        "\n",
        "plt.ylabel('Sentiments', fontsize=16)\n",
        "plt.title('Proportional Distribution of Sentiments', fontsize=18)"
      ],
      "metadata": {
        "id": "hqaVBSwBdSYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "Our final dataset contains about 72.4% positive reviews, 20.1 % negative reviews, and 7.6% neutral reviews\n",
        "\n",
        "Saving the Final Dataset as a CSV File\n",
        "We will save our final dataset as a csv file in the local system.\n",
        "This will allow us to resume from this point onwards if we want to make changes to the model building process."
      ],
      "metadata": {
        "id": "6v6MMPo9efGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the dataframe to a csv file\n",
        "sentiment_df.to_csv('review_data.csv', index=False, encoding='utf-8')\n",
        "\n",
        "# To load the saved csv file into a dataframe\n",
        "sentiment_df = pd.read_csv('review_data.csv')\n",
        "sentiment_df.head()"
      ],
      "metadata": {
        "id": "oxIX_vsUgBvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Splitting.\n",
        "\n",
        "Now,we will  split the dataset into Train and Test subsets.\n",
        "We will use 80% data for training and the remaining 20% data for testing our models.\n",
        "\n",
        "First, we will separate the reviews and their respective sentiment labels from the data."
      ],
      "metadata": {
        "id": "koSPk0YIjWJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separating the Reviews from the dataset\n",
        "X = sentiment_df['clean_reviews'].values\n",
        "X[:5]"
      ],
      "metadata": {
        "id": "lO0Vh_aOj8Ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separating the labels\n",
        "y = sentiment_df['sentiment'].values\n",
        "y[:5]"
      ],
      "metadata": {
        "id": "u05i2mz2kFOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After separating the reviews and labels, we will split the data into train and test sets.\n",
        "# Using scikit-learn's train_test_split function to split the dataset into train and test sets.\n",
        "# 80% of the data will be in the train set and 20% in the test set, as specified by test_size=0.2\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "BPQr4NRAkSW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the shapes of the training and test sets.\n",
        "print('Training Data Shape:', X_train.shape, y_train.shape)\n",
        "print('Testing Data Shape:', X_test.shape, y_test.shape)\n",
        "\n",
        "# The data has been divided into training and test sets."
      ],
      "metadata": {
        "id": "7mtx0S4Ok1-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Development & Evaluation - in this section we will be building our Machine Learning models and fitting them with the training data.\n",
        "\n",
        "# Building Machine Learning Model.\n",
        "# Building a tokenizer function will split each review into a list of tokens.\n",
        "# A token is a single word in this case, and the review will be splitted on a single white space."
      ],
      "metadata": {
        "id": "QqBqXZWOlMOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer(text):\n",
        "    return text.split()"
      ],
      "metadata": {
        "id": "vAqVtjqNlxx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a TFIDF Vectorizer.\n",
        "In this, first we create a vocabulary of unique tokens from the entire set of documents(i.e reviews)\n",
        "Then we construct a feature vector from each document that contains the term frequency of how often each word occurs in a particular document.\n",
        "Term Frequency is the number of times a term t, occurs in a document d.\n",
        "TFIDF stands for term frequency-inverse document frequency(tf-idf)\n",
        "It is used to downweight the frequently occuring words in the feature vectors that typically don't contain useful or discriminatory information.\n",
        "\n",
        "tf- idf(t,d) = tf(t,d) * id(t,d)\n",
        "Here, tf(t,d) is the term frequency, and\n",
        "idf(t,d) is the inverse document frequency.\n",
        "\n",
        "idf(t,d) = log(ndl(1+df(d,t))\n",
        "Here nd is the total number of documents, and\n",
        "df(d,t) is the number of documents, d that contain the term t.\n",
        "\n",
        "This will create a matrix of 15000 most common words, based on their term frequency in the data, as the columns."
      ],
      "metadata": {
        "id": "Zlg9Ky5jl3Cq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(max_features=15000, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "h4x_vUyeqIvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a Machine Learning Pipeline\n",
        "This will first, vectorize the data, creating a TFIDF feature matrix from the dataset, then will pass to our classifier.\n",
        "The classifier in this case is the Multinomial Naive Bayes classifier\n",
        "This algorithm is most suited for vectorized text that contains a large number of features.\n",
        "Creating a pipeline allows us to streamline our Machine learning workflow by performing multiple steps in a single pass."
      ],
      "metadata": {
        "id": "oL4sLCZIr4fu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_mnb = Pipeline([('vect', tfidf), ('clf', MultinomialNB())])"
      ],
      "metadata": {
        "id": "kWCVUheYs_q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting our pipeline with the training data\n",
        "tfidf_mnb.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "b__1bMIftWym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making Predictions on the Test set\n",
        "y_pred = tfidf_mnb.predict(X_test)"
      ],
      "metadata": {
        "id": "PTcl4GFDtfYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred[:5]"
      ],
      "metadata": {
        "id": "nSoMHLMptwek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation\n",
        "\n",
        "Checking the model accuracy on both train and test sets.\n",
        "We are using the classifier's score method, which calculates the accuracy score of the model on a given data"
      ],
      "metadata": {
        "id": "epbln1U5tzjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Model Accuracy for the Train set:', tfidf_mnb.score(X_train, y_train))"
      ],
      "metadata": {
        "id": "LsGAU-1OuGnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Model Accuracy for the Test set:', tfidf_mnb.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "cxNmy8TDuPPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "We get an accuracy of about 92% on both of our train set and test set.\n",
        "This implies that our model is not overfitting\n",
        "It is generating well on unseen data, and giving good results."
      ],
      "metadata": {
        "id": "kzqOVZBzuXib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Dataframe(confusion_matrix(y_test, y_pred), columns=['negative','neutral','positive'], index=['negative', 'neutral','positive'])"
      ],
      "metadata": {
        "id": "L269AsWdvN26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "aKc5jmH4vh3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model is giving best results for the positive sentiment.\n",
        "This might be due to the large proportion of positive reviews in the dataset.\n",
        "The performance for negative reviews is also good with a F1 score of 85%\n",
        "But, our model struggles while predicting the neutral sentiment\n",
        "This is due to the fact the many neutral sentiment reviews contains words which can sometimes be associated with both positive and negative reviews.\n",
        "Also, there are a lot less number of neutral reviews in the data.\n",
        "And, hence leads to a lot of false negatives in the neutral statement."
      ],
      "metadata": {
        "id": "NZzXd4IivmiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a dataframe containing the test set reviews and sentiments, along with the predictions made by the model for comparison\n",
        "\n",
        "evaluation_df = pd.DataFrame({'reviews': X_test, 'sentiment': y_test, 'sentiment_tfidf_mnb': y_pred})\n",
        "evaluation_df.head()"
      ],
      "metadata": {
        "id": "3mxzg4wfw_V9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "The sentiments we gave to the reviews were based on star ratings and the polarity value calculating TextBlob's sentiment analysis function.\n",
        "Now, we can visually compare the sentiment predictions made by our model on these reviews."
      ],
      "metadata": {
        "id": "7v-VD6QJxiaM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion:\n",
        "\n",
        "We cleaned the reviews by\n",
        "Changing the case of each word to lowercase.\n",
        "Fixing certain words\n",
        "Removing all the punctuation marks from each review, and\n",
        "Removing any additional white space from each review.\n",
        "Then, we calculate the polarity and subjectivity values for each review\n",
        "This allowed us to analyze our data in-depth to find relationship between various features like star rating and polarity\n",
        "We also calculated a threshold for the subjectivity value in our reviews\n",
        "we then found out the most common words associated with different sentiments\n",
        "After analyzing the data:\n",
        "We remove all redundant columns from the data\n",
        "Remove all the samples having subjectivity less than 0.3 i.e the subjectivity threshold\n",
        "Divide reviews into sentiments based on star rating and polarity\n",
        "At last, we split the data into training and test sets.\n",
        "During model building, we first created a TFIDF matrix of our data and trained a Multinomial Naive Bayes model\n",
        "This model was then used to make predictions on the test set\n",
        "It achieved an accuracy of 92% on both train and test sets\n",
        "This implied that model is not overfitting and is generalizing well on unseen data."
      ],
      "metadata": {
        "id": "4FIdpJekx1_x"
      }
    }
  ]
}